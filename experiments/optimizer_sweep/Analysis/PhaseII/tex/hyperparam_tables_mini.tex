\subsection{Sweeping Results for Adam-Mini}% mini - 300m on 2x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for Adam-Mini on 300m on 2x Chinchilla Data}
\label{tab:ablation_adam-mini_300m_on_2x_chinchilla_data}
\begin{tabular}{ccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.9 & 0.98 & 1e-25 & 0.004 & 2 & 0 & 128 & 2000 & 0.2 & 3.178 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-12B-mini9676c0lr0.004-wd0.2-minlr0-warmup2000-b10.9-b-80350d}{0} \\
\midrule
-- & -- & -- & 0.002 & -- & -- & -- & -- & -- & 3.180 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-12B-mini4cf513lr0.002-wd0.2-minlr0-warmup2000-b10.9-b-df6367}{1} \\
-- & -- & -- & -- & -- & -- & 256 & -- & -- & 6.960 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-12B-mini65d3bflr0.004-wd0.2-minlr0-warmup2000-b10.9-b-79c803}{2} \\
-- & -- & -- & -- & -- & -- & -- & 4000 & -- & 3.183 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-12B-minic35a69lr0.004-wd0.2-minlr0-warmup4000-b10.9-b-05ae30}{3} \\
-- & -- & -- & -- & -- & -- & -- & -- & 0.1 & 3.179 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-12B-minif8c6e5lr0.004-wd0.1-minlr0-warmup2000-b10.9-b-aa6c53}{4} \\
\bottomrule
\end{tabular}
\end{table}

% mini - 300m on 4x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for Adam-Mini on 300m on 4x Chinchilla Data}
\label{tab:ablation_adam-mini_300m_on_4x_chinchilla_data}
\begin{tabular}{ccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.9 & 0.98 & 1e-25 & 0.004 & 2 & 0 & 128 & 2000 & 0.1 & 3.103 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-24B-mini09d394lr0.004-wd0.1-minlr0-warmup2000-b10.9-b-4e8de7}{0} \\
\midrule
-- & -- & -- & 0.002 & -- & -- & -- & -- & -- & 3.111 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-24B-mini5d38a2lr0.002-wd0.1-minlr0-warmup2000-b10.9-b-951b01}{1} \\
-- & -- & -- & -- & -- & -- & 256 & -- & -- & 3.109 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-24B-minid571a7lr0.004-wd0.1-minlr0-warmup2000-b10.9-b-e475d2}{2} \\
-- & -- & -- & -- & -- & -- & -- & 4000 & -- & 3.104 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-24B-mini0831d8lr0.004-wd0.1-minlr0-warmup4000-b10.9-b-41a654}{3} \\
-- & -- & -- & -- & -- & -- & -- & -- & 0.2 & 3.111 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-24B-mini891741lr0.004-wd0.2-minlr0-warmup2000-b10.9-b-a97787}{4} \\
\bottomrule
\end{tabular}
\end{table}

% mini - 300m on 8x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for Adam-Mini on 300m on 8x Chinchilla Data}
\label{tab:ablation_adam-mini_300m_on_8x_chinchilla_data}
\begin{tabular}{ccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.9 & 0.98 & 1e-25 & 0.002 & 2 & 0 & 128 & 2000 & 0.2 & 3.049 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-48B-minic8695flr0.002-wd0.2-minlr0-warmup2000-b10.9-b-952cc4}{0} \\
\midrule
-- & -- & -- & 0.004 & -- & -- & -- & -- & -- & 3.064 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-48B-minid13807lr0.004-wd0.2-minlr0-warmup2000-b10.9-b-c8b391}{1} \\
-- & -- & -- & -- & -- & -- & 256 & -- & -- & 3.052 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-48B-mini54b665lr0.002-wd0.2-minlr0-warmup2000-b10.9-b-bb57bb}{2} \\
-- & -- & -- & -- & -- & -- & -- & 4000 & -- & 3.050 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-48B-mini8ec643lr0.002-wd0.2-minlr0-warmup4000-b10.9-b-efe5ba}{3} \\
-- & -- & -- & -- & -- & -- & -- & -- & 0.1 & 3.051 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-48B-mini293878lr0.002-wd0.1-minlr0-warmup2000-b10.9-b-f38163}{4} \\
\bottomrule
\end{tabular}
\end{table}

% mini - 520m on 2x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for Adam-Mini on 520m on 2x Chinchilla Data}
\label{tab:ablation_adam-mini_520m_on_2x_chinchilla_data}
\begin{tabular}{ccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.9 & 0.98 & 1e-10 & 0.004 & 1 & 0 & 128 & 4000 & 0.1 & 3.027 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-21B-mini4e584elr0.004-wd0.1-minlr0-warmup4000-b10.9-b-eceb71}{0} \\
\midrule
-- & -- & -- & 0.002 & -- & -- & -- & -- & -- & 3.031 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-21B-mini3dba17lr0.002-wd0.1-minlr0-warmup4000-b10.9-b-557d40}{1} \\
-- & -- & -- & -- & -- & -- & 256 & -- & -- & 3.032 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-21B-mini89512clr0.004-wd0.1-minlr0-warmup4000-b10.9-b-66cd27}{2} \\
-- & -- & -- & -- & -- & -- & -- & 2000 & -- & 7.359 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-21B-mini5c5f85lr0.004-wd0.1-minlr0-warmup2000-b10.9-b-9ff993}{3} \\
-- & -- & -- & -- & -- & -- & -- & -- & 0.2 & 3.037 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-21B-miniqbb0854lr0.004-wd0.2-minlr0-warmup4000-b10.9--8a1042}{4} \\
\bottomrule
\end{tabular}
\end{table}

% mini - 520m on 4x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for Adam-Mini on 520m on 4x Chinchilla Data}
\label{tab:ablation_adam-mini_520m_on_4x_chinchilla_data}
\begin{tabular}{ccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.9 & 0.98 & 1e-10 & 0.004 & 1 & 0 & 128 & 4000 & 0.1 & 2.966 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-42B-minikdfe5aclr0.004-wd0.1-minlr0-warmup4000-b10.9--5de7af}{0} \\
\midrule
-- & -- & -- & 0.002 & -- & -- & -- & -- & -- & 2.963 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-42B-minik6bf656lr0.002-wd0.1-minlr0-warmup4000-b10.9--a9507c}{1} \\
-- & -- & -- & -- & -- & -- & 256 & -- & -- & 2.963 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-42B-minik4e584elr0.004-wd0.1-minlr0-warmup4000-b10.9--3eca5c}{2} \\
-- & -- & -- & -- & -- & -- & -- & 2000 & -- & 7.529 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-42B-minikb765f6lr0.004-wd0.1-minlr0-warmup2000-b10.9--520ca1}{3} \\
-- & -- & -- & -- & -- & -- & -- & -- & 0.2 & 2.981 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-42B-miniba6697lr0.004-wd0.2-minlr0-warmup4000-b10.9-b-2db890}{4} \\
\bottomrule
\end{tabular}
\end{table}

% mini - 520m on 8x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for Adam-Mini on 520m on 8x Chinchilla Data}
\label{tab:ablation_adam-mini_520m_on_8x_chinchilla_data}
\begin{tabular}{ccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.9 & 0.98 & 1e-10 & 0.004 & 1 & 0 & 256 & 4000 & 0.1 & 2.912 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-85B-minidfe5aclr0.004-wd0.1-minlr0-warmup4000-b10.9-b-a76572}{0} \\
\midrule
-- & -- & -- & 0.002 & -- & -- & -- & -- & -- & 2.918 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-85B-mini6bf656lr0.002-wd0.1-minlr0-warmup4000-b10.9-b-aa645d}{1} \\
-- & -- & -- & -- & -- & -- & 128 & -- & -- & 2.921 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-85B-mini6698b4lr0.004-wd0.1-minlr0-warmup4000-b10.9-b-0f2989}{2} \\
-- & -- & -- & -- & -- & -- & -- & 2000 & -- & 7.449 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-85B-minib765f6lr0.004-wd0.1-minlr0-warmup2000-b10.9-b-e401ae}{3} \\
-- & -- & -- & -- & -- & -- & -- & -- & 0.2 & 3.025 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-85B-miniba6697lr0.004-wd0.2-minlr0-warmup4000-b10.9-b-137303}{4} \\
\bottomrule
\end{tabular}
\end{table}

