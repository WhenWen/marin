\subsection{Sweeping Results for Soap}% soape - 300m on 2x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for Soap on 300m on 2x Chinchilla Data}
\label{tab:ablation_soap_300m_on_2x_chinchilla_data}
\begin{tabular}{ccccccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\mathrm{block size}$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{Blocking}$ & $f_{pc}$ & $\beta_{shampoo}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.95 & 0.99 & 512 & 1e-10 & 0.008 & 1 & 0 & True & 10 & 0.9 & 128 & 1000 & 0.1 & 3.147 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-12B-soapefe4b166lr0.008-wd0.1-minlr0-warmup1000-b10.9-cebb81}{0} \\
\midrule
-- & -- & 128 & -- & -- & -- & -- & -- & -- & -- & -- & -- & -- & 3.154 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-12B-soapeb93333lr0.008-wd0.1-minlr0-warmup1000-b10.95-feb227}{1} \\
-- & -- & 256 & -- & -- & -- & -- & -- & -- & -- & -- & -- & -- & 3.150 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-12B-soape1f2d4flr0.008-wd0.1-minlr0-warmup1000-b10.95-78cbf5}{2} \\
-- & -- & -- & -- & 0.004 & -- & -- & -- & -- & -- & -- & -- & -- & 3.147 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-12B-soapef97cdfclr0.004-wd0.1-minlr0-warmup1000-b10.9-dec1d6}{3} \\
-- & -- & -- & -- & -- & -- & -- & -- & -- & -- & 256 & -- & -- & 3.153 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-12B-soape63ad3blr0.008-wd0.1-minlr0-warmup1000-b10.95-b1cbe1}{4} \\
\bottomrule
\end{tabular}
\end{table}

% soape - 300m on 4x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for Soap on 300m on 4x Chinchilla Data}
\label{tab:ablation_soap_300m_on_4x_chinchilla_data}
\begin{tabular}{ccccccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\mathrm{block size}$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{Blocking}$ & $f_{pc}$ & $\beta_{shampoo}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.95 & 0.99 & 512 & 1e-10 & 0.008 & 1 & 0 & True & 10 & 0.9 & 256 & 1000 & 0.1 & 3.084 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-24B-soapeie4b166lr0.008-wd0.1-minlr0-warmup1000-b10.9-9894a6}{0} \\
\midrule
-- & -- & 128 & -- & -- & -- & -- & -- & -- & -- & -- & -- & -- & 3.086 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-24B-soapeib93333lr0.008-wd0.1-minlr0-warmup1000-b10.9-811046}{1} \\
-- & -- & 256 & -- & -- & -- & -- & -- & -- & -- & -- & -- & -- & 3.084 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-24B-soapei1f2d4flr0.008-wd0.1-minlr0-warmup1000-b10.9-63b43e}{2} \\
-- & -- & -- & -- & 0.004 & -- & -- & -- & -- & -- & -- & -- & -- & 3.086 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-24B-soapei97cdfclr0.004-wd0.1-minlr0-warmup1000-b10.9-97c1bf}{3} \\
-- & -- & -- & -- & -- & -- & -- & -- & -- & -- & 128 & -- & -- & 3.091 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-24B-soapeie57080lr0.008-wd0.1-minlr0-warmup1000-b10.9-7a725d}{4} \\
\bottomrule
\end{tabular}
\end{table}

% soape - 300m on 8x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for Soap on 300m on 8x Chinchilla Data}
\label{tab:ablation_soap_300m_on_8x_chinchilla_data}
\begin{tabular}{ccccccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\mathrm{block size}$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{Blocking}$ & $f_{pc}$ & $\beta_{shampoo}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.95 & 0.99 & 512 & 1e-10 & 0.008 & 1 & 0 & True & 10 & 0.9 & 256 & 1000 & 0.1 & 3.030 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-48B-soapeae57080lr0.008-wd0.1-minlr0-warmup1000-b10.9-f53d36}{0} \\
\midrule
-- & -- & 128 & -- & -- & -- & -- & -- & -- & -- & -- & -- & -- & 3.034 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-48B-soape98b16alr0.008-wd0.1-minlr0-warmup1000-b10.95-76e70a}{1} \\
-- & -- & 256 & -- & -- & -- & -- & -- & -- & -- & -- & -- & -- & 3.032 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-48B-soapec59568lr0.008-wd0.1-minlr0-warmup1000-b10.95-dc6b11}{2} \\
-- & -- & -- & -- & 0.004 & -- & -- & -- & -- & -- & -- & -- & -- & 3.031 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-48B-soape9f5a41lr0.004-wd0.1-minlr0-warmup1000-b10.95-c462c4}{3} \\
-- & -- & -- & -- & -- & -- & -- & -- & -- & -- & 128 & -- & -- & 3.043 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-48B-soapea631a39lr0.008-wd0.1-minlr0-warmup1000-b10.9-9b5fd4}{4} \\
\bottomrule
\end{tabular}
\end{table}

% soape - 520m on 2x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for Soap on 520m on 2x Chinchilla Data}
\label{tab:ablation_soap_520m_on_2x_chinchilla_data}
\begin{tabular}{ccccccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\mathrm{block size}$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{Blocking}$ & $f_{pc}$ & $\beta_{shampoo}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.95 & 0.99 & 512 & 1e-10 & 0.008 & 1 & 0 & True & 10 & 0.95 & 256 & 1000 & 0.1 & 3.004 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-21B-soapea9baa74lr0.008-wd0.1-minlr0-warmup1000-b10.9-7994bc}{0} \\
\midrule
-- & -- & 128 & -- & -- & -- & -- & -- & -- & -- & -- & -- & -- & 3.013 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-21B-soapeaf56540lr0.008-wd0.1-minlr0-warmup1000-b10.9-f05b1f}{1} \\
-- & -- & 256 & -- & -- & -- & -- & -- & -- & -- & -- & -- & -- & 3.010 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-21B-soapea3d9681lr0.008-wd0.1-minlr0-warmup1000-b10.9-efedef}{2} \\
-- & -- & -- & -- & 0.004 & -- & -- & -- & -- & -- & -- & -- & -- & 3.008 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-21B-soapea5a76ddlr0.004-wd0.1-minlr0-warmup1000-b10.9-f115eb}{3} \\
-- & -- & -- & -- & -- & -- & -- & -- & -- & -- & 128 & -- & -- & 3.011 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-21B-soapeaef50b6lr0.008-wd0.1-minlr0-warmup1000-b10.9-8aed93}{4} \\
\bottomrule
\end{tabular}
\end{table}

% soape - 520m on 4x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for Soap on 520m on 4x Chinchilla Data}
\label{tab:ablation_soap_520m_on_4x_chinchilla_data}
\begin{tabular}{ccccccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\mathrm{block size}$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{Blocking}$ & $f_{pc}$ & $\beta_{shampoo}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.95 & 0.99 & 512 & 1e-10 & 0.004 & 1 & 0 & True & 10 & 0.95 & 256 & 1000 & 0.1 & 2.944 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-42B-soapepde58c5lr0.004-wd0.1-minlr0-warmup1000-b10.9-c834a4}{0} \\
\midrule
-- & -- & 128 & -- & -- & -- & -- & -- & -- & -- & -- & -- & -- & 2.948 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-42B-soapedb348f5lr0.004-wd0.1-minlr0-warmup1000-b10.9-b0ebf2}{1} \\
-- & -- & 256 & -- & -- & -- & -- & -- & -- & -- & -- & -- & -- & 2.945 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-42B-soaped5aacdclr0.004-wd0.1-minlr0-warmup1000-b10.9-94f724}{2} \\
-- & -- & -- & -- & 0.008 & -- & -- & -- & -- & -- & -- & -- & -- & 2.949 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-42B-soapepef50b6lr0.008-wd0.1-minlr0-warmup1000-b10.9-0c8c99}{3} \\
-- & -- & -- & -- & -- & -- & -- & -- & -- & -- & 128 & -- & -- & 2.946 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-42B-soapepa7a19flr0.004-wd0.1-minlr0-warmup1000-b10.9-868eca}{4} \\
\bottomrule
\end{tabular}
\end{table}

% soape - 520m on 8x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for Soap on 520m on 8x Chinchilla Data}
\label{tab:ablation_soap_520m_on_8x_chinchilla_data}
\begin{tabular}{ccccccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\mathrm{block size}$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{Blocking}$ & $f_{pc}$ & $\beta_{shampoo}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.95 & 0.99 & 512 & 1e-10 & 0.004 & 1 & 0 & True & 10 & 0.95 & 256 & 1000 & 0.1 & 2.899 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-85B-soapeaa7a19flr0.004-wd0.1-minlr0-warmup1000-b10.9-fe941f}{0} \\
\midrule
-- & -- & -- & -- & 0.008 & -- & -- & -- & -- & -- & -- & -- & -- & 2.906 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-520m-85B-soapew298532lr0.008-wd0.1-minlr0-warmup1000-b10.9-59eeb6}{1} \\
\bottomrule
\end{tabular}
\end{table}

