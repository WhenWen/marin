\subsection{Sweeping Results for Soap}% soape - 130m on 16x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for Soap on 130m on 16x Chinchilla Data}
\label{tab:ablation_soap_130m_on_16x_chinchilla_data}
\begin{tabular}{ccccccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\mathrm{block size}$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{Blocking}$ & $f_{pc}$ & $\beta_{shampoo}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.95 & 0.99 & 512 & 1e-10 & 0.008 & 1 & 0 & True & 10 & 0.98 & 256 & 1000 & 0.1 & 3.191 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-42B-soape1786aelr0.008-wd0.1-minlr0-warmup1000-b10.95-c390d2}{0} \\
\midrule
\bottomrule
\end{tabular}
\end{table}

% soape - 300m on 16x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for Soap on 300m on 16x Chinchilla Data}
\label{tab:ablation_soap_300m_on_16x_chinchilla_data}
\begin{tabular}{ccccccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\mathrm{block size}$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{Blocking}$ & $f_{pc}$ & $\beta_{shampoo}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.95 & 0.99 & 512 & 1e-10 & 0.004 & 1 & 0 & True & 10 & 0.9 & 256 & 1000 & 0.1 & 2.990 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-96B-soapef479bb0lr0.004-wd0.1-minlr0-warmup1000-b10.9-ef8190}{0} \\
\midrule
\bottomrule
\end{tabular}
\end{table}

