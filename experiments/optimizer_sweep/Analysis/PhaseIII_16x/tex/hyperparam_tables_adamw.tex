\subsection{Sweeping Results for AdamW}% adamw - 130m on 16x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for AdamW on 130m on 16x Chinchilla Data}
\label{tab:ablation_adamw_130m_on_16x_chinchilla_data}
\begin{tabular}{ccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.9 & 0.98 & 1e-10 & 0.008 & 1 & 0 & 256 & 1000 & 0.1 & 3.207 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-130m-42B-adamwdf6bfb1lr0.008-wd0.1-minlr0-warmup1000-b10.9-c5d61d}{0} \\
\midrule
\bottomrule
\end{tabular}
\end{table}

% adamw - 300m on 16x Chinchilla Data
\begin{table}[H]
\centering
\caption{Hyperparameter ablation for AdamW on 300m on 16x Chinchilla Data}
\label{tab:ablation_adamw_300m_on_16x_chinchilla_data}
\begin{tabular}{ccccccccccc}
\toprule
$\beta_1$ & $\beta_2$ & $\epsilon$ & $\eta$ & $\gradnorm$ & $\eta_{min}$ & $\mathrm{BSZ}$ & $\mathrm{warmup}$ & $\lambda$ & Loss & Link \\
\midrule
0.9 & 0.98 & 1e-10 & 0.004 & 2 & 0 & 256 & 2000 & 0.1 & 3.001 & \href{https://wandb.ai/stanford-mercury/optimizer-scaling/runs/sweep-300m-96B-adamwfcee97lr0.004-wd0.1-minlr0-warmup2000-b10.9--18b705}{0} \\
\midrule
\bottomrule
\end{tabular}
\end{table}

